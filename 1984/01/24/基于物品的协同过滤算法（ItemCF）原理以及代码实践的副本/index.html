<!DOCTYPE html>
<html lang="zh-cn">
  <head>
    <meta charset="utf8" />
    <meta name="viewport" content="initial-scale=1.0, width=device-width" />
    <title>
      
        推荐系统之评估方法和评价指标PR、ROC、AUC | 思想放牧之地
      
    </title>
    <meta name="description" content="有情有颜 有才缺钱" />
    <meta name="keywords" content="" />
    
      <link rel="apple-touch-icon"
            sizes="180x180"
            href="/images/apple-touch-icon.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="32x32"
            href="/images/favicon-32x32.png" />
    
    
      <link rel="icon"
            type="image/png"
            sizes="16x16"
            href="/images/favicon-16x16.png" />
    
    
      <link rel="mask-icon"
            href="/images/logo.svg"
            color="" />
    
    
    
      
  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/normal.ttf);
        font-weight: normal;
    }
  </style>

  <style>
    @font-face {
        font-family:sourceHanSerif;
        src: url(/font/bold.ttf);
        font-weight: bold;
    }
  </style>


    
    <link rel="stylesheet"
          type="text/css"
          href='/css/layout.css' />
    
    
  <link rel="stylesheet" type="text/css" href="/css/post.css"/>
  

  <meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    
      <div id="search-mask" style="display:none">
  <div class="search-main" id="search-main">
    <div class="search__head">
      <div class="search-form">
        <svg t="1706347533072"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="7828"
             width="20"
             height="20">
          <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
          </path>
        </svg>
        <input id="search-input" placeholder="搜索文章">
        <svg t="1706361500528"
             id="search-clear"
             class="icon"
             viewBox="0 0 1024 1024"
             version="1.1"
             xmlns="http://www.w3.org/2000/svg"
             p-id="4351"
             width="20"
             height="20">
          <path d="M512 562.688l-264.2944 264.2944-50.688-50.688L461.312 512 197.0176 247.7056l50.688-50.688L512 461.312l264.2944-264.2944 50.688 50.688L562.688 512l264.2944 264.2944-50.688 50.688L512 562.688z" fill="#00" p-id="4352">
          </path>
        </svg>
      </div>
    </div>
    <div class="search__body" id="search-result"></div>
    <div class="search__foot"></div>
  </div>
</div>

    
    
    <div class=head--sticky>
      <div class="nav">
        <a href='/' class="nav-logo">
          <img alt="logo" height="60px" width="60px" src="/images/logo.svg" />
        </a>
        <input id="navBtn" type="checkbox" />
        <div class="nav-right">
          
            <div class="search-outer">
  <div class="search" id="search-btn">
    <svg t="1706347533072"
         class="icon"
         viewBox="0 0 1024 1024"
         version="1.1"
         xmlns="http://www.w3.org/2000/svg"
         p-id="7828"
         width="20"
         height="20">
      <path d="M685.6 660.336l155.152 155.168a16 16 0 0 1 0 22.624l-11.312 11.328a16 16 0 0 1-22.624 0l-158.528-158.544a289.792 289.792 0 0 1-165.152 51.36C322.336 742.256 192 611.904 192 451.12 192 290.336 322.336 160 483.136 160c160.784 0 291.12 130.336 291.12 291.136 0 82.112-33.984 156.272-88.672 209.2z m-202.464 33.92c134.272 0 243.12-108.848 243.12-243.12C726.256 316.848 617.408 208 483.136 208 348.848 208 240 316.848 240 451.136c0 134.272 108.848 243.12 243.136 243.12z" fill="#000000" p-id="7829">
      </path>
    </svg>
    <span>搜索</span>
    <span class="search-shortcut-key">Ctrl K</span>
  </div>
</div>

          
          <div class="nav-menu">
            
              
                <a class="nav-menu-item" href="/AI">AI大模型</a>
              
                <a class="nav-menu-item" href="/photograph">拍摄摄影</a>
              
                <a class="nav-menu-item" href="/live">生活随记</a>
              
                <a class="nav-menu-item" target="_blank" rel="noopener" href="https://bbs.hanlp.com/">社区维护</a>
              
            
            <a class="nav-menu-item" href='/cv/'>简历</a>
          </div>
        </div>
        <label class="nav-btn" for="navBtn"></label>
      </div>
    </div>
    <div class="body">
      
  <article class="post-content">
    <div class="post-inner">
      <div class="post-content__head">
        <div class="post-title">推荐系统之评估方法和评价指标PR、ROC、AUC</div>
        <div class="post-info">
          
  <a href="/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/" class="post-tag">#评价指标</a>


          <span class="post-date">1984-01-24</span>
        </div>
      </div>
      
      <div class="post-content__body">
        
          <div class="post-gallery">
            
          </div>
        
        <h1 id="推荐系统文档">推荐系统文档</h1>
<h2
id="推荐系统之评估方法和评价指标prrocauc">1、推荐系统之评估方法和评价指标PR、ROC、AUC</h2>
<blockquote>
<p>链接：https://www.jianshu.com/p/5b0bc79e3d75</p>
</blockquote>
<h1 id="简介">简介</h1>
<p>推荐系统的评估相关的知识比重在整个推荐系统的知识框架中占比不大，但是其重要程度不言而喻，因为采用的评价指标直接影响到了推荐系统的优化方向是否正确。<strong>评价指标主要用于评价推荐系统各方面的性能</strong>，按照应用场景可以分为离线评估和线上测试。其中离线评估的主要方法包括<strong>Holdout检验、交叉检验、留一验证、自助法</strong>等，评价指标主要包括<strong>用户满意度、预测准确度、召回率、覆盖率、多样性、新颖性、流行度、均方根误差、对数损失、P-R曲线、AUC、ROC曲线</strong>等等。线上测试的评估方法主要包括<strong>A/B测试、Interleaving方法</strong>等，评价指标主要包括<strong>点击率、转化率、留存率、平均点击个数</strong>等等。本文将着重介绍<strong>离线评估相关方法和指标</strong>，尤其是<strong>P-R曲线、AUC、ROC曲线</strong>等，这些评价指标是最常用的也是最基本的，出现在各类推荐相关的论文中，因此需要重点掌握。</p>
<hr />
<h1 id="离线评估方法和评价指标">离线评估方法和评价指标</h1>
<p>在推荐系统的评估过程中，离线评估往往被当做最常用也是最基本的评估方法。顾名思义，离线评估是指在将模型部署于线上环境之前，在离线环境中进行的评估。由于不用部署到生产环境，离线评估没有线上部署的工程风险，也无须浪费宝贵的线上流量资源，而且具有测试时间短，同时进行多组并行测试、能够利用丰富的线下计算资源等诸多优点。</p>
<h2 id="离线评估的主要方法">离线评估的主要方法</h2>
<ul>
<li>Holdout检验
Holdout检验是基础的离线评估方法，它将原始的样本集合随机划分为训练集和测试集两部分。举例来说，对于一个推荐模型，可以把样本按照70%~30%的比例随机分成两部分，70%的样本用于模型的训练，30%的样本可以用于模型的评估。
在实际应用中，有很多方便的库可以帮助我们进行样本集合的划分，比如scikit-learn中提供的train_test_split函数，下面进行个简单展示：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">x,y = np.arange(<span class="number">10</span>).reshape((<span class="number">5</span>,<span class="number">2</span>)), <span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data: \n&quot;</span>, x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels: &quot;</span>, <span class="built_in">list</span>(y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对数据集进行划分，设置测试集占比30%，训练集占比70%</span></span><br><span class="line">X_train, X_test,Y_train,Y_test = train_test_split(x, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">100</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train Data: &quot;</span>, X_train, Y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Data: &quot;</span>, X_test, Y_test)</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xahrs25j20cc0bkglx.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>Holdout检验的缺点也很明显，即在验证集上计算出来的评估指标与训练集合验证集的划分有直接关系，如果仅仅进行少量Holdout检验，则得到的结论存在较大的随机性。为了消除这种随机性，“交叉检验”的思想被提出。</p>
<ul>
<li>交叉验证
<strong>k-fold交叉验证</strong>：先将全部的样本划分为k个大小相等的样本子集；依次遍历这k个子集，每次都把当前子集作为验证集，其余所有子集作为训练集，进行模型的训练和评估；最后将所有的k次的评估指标的平均值作为最终的评估指标。在实验中，k经常取10。同样,scikit-learn中提供了KFold函数可以使用，例子如下：</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line">X = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">kf = KFold(n_splits=<span class="number">4</span>)</span><br><span class="line">kf.get_n_splits(X)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> kf.split(X):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;TRAIN:&quot;</span>, train_index, <span class="string">&quot;TEST:&quot;</span>, test_index)</span><br><span class="line">    X_train, X_test = X[train_index], X[test_index]</span><br><span class="line">    y_train, y_test = y[train_index], y[test_index]</span><br></pre></td></tr></table></figure>
<p>输出：<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xaws6m1j20bo04e74g.jpg"
alt="img" /></p>
<p><strong>留一验证</strong>：每次留下1个样本作为验证集，其余所有样本作为测试集。样本总数为n，依次遍历所有n个样本，进行n次验证，在将评估指标求平均得到最终指标，在样本总数较多的情况下，留一验证法的时间开销极大。事实上，留一验证是留p验证的特例。留p验证是指每次留下p个样本作为验证集，而从n个元素中选取p个元素共有<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xbd6tkkj201m0183y9.jpg" alt="image-20220609132353358" style="zoom:50%;" />种可能，因此它的时间开销远超留一验证，故很少在实际工程中使用。
同样，scikit-learn中提供了LeaveOneOut方法可使用，例子如下：</p>
<figure class="highlight swift"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy as np</span><br><span class="line"></span><br><span class="line">from sklearn.model_selection <span class="keyword">import</span> LeaveOneOut</span><br><span class="line"><span class="type">X</span> <span class="operator">=</span> np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">y <span class="operator">=</span> np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">loo <span class="operator">=</span> <span class="type">LeaveOneOut</span>()</span><br><span class="line">loo.get_n_splits(<span class="type">X</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> loo.split(<span class="type">X</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;TRAIN:&quot;</span>, train_index, <span class="string">&quot;TEST:&quot;</span>, test_index)</span><br><span class="line">    <span class="type">X_train</span>, <span class="type">X_test</span> <span class="operator">=</span> <span class="type">X</span>[train_index], <span class="type">X</span>[test_index]</span><br><span class="line">    y_train, y_test <span class="operator">=</span> y[train_index], y[test_index]</span><br><span class="line">    <span class="built_in">print</span>(<span class="type">X_train</span>, <span class="type">X_test</span>, y_train, y_test)</span><br></pre></td></tr></table></figure>
<p>结果：</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xbt3o5oj20cs090q3d.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>自助法
不管是Holdout检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，当样本规模比较小的时候，将样本集进行划分会让训练集进一步减小，这可能会影响到模型的训练效果。有没有能维持训练集样本规模的验证方法呢？“自助法”可以在一定程度上解决这个问题。
自助法是基于自助采样法的检验方法：对于总数为n的样本集合，进行n次有放回的随机抽样，得到大小为n的训练集。在n次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集进行模型验证，这就是自助法的验证过程。</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xdawo9tj210q098dhc.jpg" alt="image-20220609132533595" style="zoom:50%;" /></p>
<h2 id="离线评估的指标">离线评估的指标</h2>
<ul>
<li><p>均方根误差
很多推荐网站都会提供一个让用户给物品打分的功能，如果知道了用户对物品的历史评分数据，就可以从中学习到用户的兴趣模型，并预测该用户在将来浏览到未曾见过的物品时，会给这个物品打多少分。评分预测可以看做是回归问题，评分预测的预测准确度一般是通过均方差误差(RMSE)和平均绝对误差(MAE)计算。对于测试集中的一个用户<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xdtnvikj20120180hl.jpg" alt="image-20220609132615154" style="zoom:50%;" />和物品<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xeak7anj201201e0jd.jpg" alt="image-20220609132641992" style="zoom:50%;" />，我们令<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xf1hsscj201m01e0r9.jpg" alt="image-20220609132724384" style="zoom:50%;" />代表用户<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xdtnvikj20120180hl.jpg" alt="image-20220609132615154" style="zoom:50%;" />对物品<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xeak7anj201201e0jd.jpg" alt="image-20220609132641992" style="zoom:50%;" />的实际评分，而<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xgkgib7j201q01i0s9.jpg" alt="image-20220609132853052" style="zoom:50%;" />代表我们的推荐算法给出的预测评分。
综上，可以得出RSME的定义为：</p>
<p>​ <img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31xh51u1cj207802jq2s.jpg"
alt="img" /></p></li>
</ul>
<p>​ 同理，MAE采用绝对值计算预测误差，定义如下：:</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yosny0bj206t02jweb.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>其中|T|代表测试集的大小。
一般情况下，RMSE能够很好滴反映回归模型预测值与真实值的偏离程度。但在实际应用时，如果存在个别偏离程度非常大的离群点，那么即使离群点数量非常少，也会让RSME指标变得很差。为了解决这个问题，可以使用鲁棒性更强的平均绝对百分比误差（Mean
Absolute Percent Error，MAPE）进行类似的评估，MAPE的定义如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yps1eklj20io05eaa2.jpg" alt="image-20220609141219926" style="zoom:50%;" /></p>
<p>相比RSME，MAPE相当于把每个点的误差都进行了归一化，降低了个别离群点带来的绝对误差的影响。</p>
<ul>
<li><p>覆盖率</p>
<p>覆盖率是描述一个推荐系统对物品长尾的发掘能力，即推荐系统做到了雨露均沾，对商城中的每一个物品都有涉及，而不是只推荐那些热门的商品。据此，覆盖率的一个简单定义为推荐系统能够推荐出来的物品占总物品集合的的比例。假设系统的用户集合<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yqp5ujvj201601a0ml.jpg" alt="image-20220609141312721" style="zoom:50%;" />，推荐系统给每个用户推荐了一个长度为N的物品列表<img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yr312qdj202g01emwx.jpg" alt="image-20220609141333960" style="zoom:50%;" />，那么覆盖率的计算公式为：:</p></li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h32g5rg0m5j20e2052jrb.jpg" alt="image-20220609141354307" style="zoom:50%;" /></p>
<p>其中｜I｜是商品的总数。</p>
<ul>
<li><p>新颖度与平均流行度</p>
<p>我们使用推荐列表中全部物品的平均流行度衡量推荐结果的新颖度。如果推荐的物品都很热门，那么说明推荐的新颖度比较低。反之，说明推荐结果比较新颖。</p>
<p>流行度的定义如下：</p></li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31ysonuj7j20go0583yh.jpg" alt="image-20220609141507747" style="zoom: 50%;" /></p>
<p>其中p是每个物品的流行度，可以通过该物品在测试集中出现的次数来简单计算，N是推荐物品集合的总数。</p>
<p>这里在计算平均流行度的时候对每个物品的流行度取对数，这是因为物品的流行度分布满足长尾分布，取对数后，流行度的平均值更加稳定。</p>
<ul>
<li><p>对数损失函数</p>
<p>对数损失函数（LogLoss）也是经常在离线评估中使用的指数，在一个二分类问题中，LogLoss的定义如下：</p></li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31ytfdu1bj20q604yaa5.jpg" alt="image-20220609141550454" style="zoom:50%;" /></p>
<p>其中，yi为输入实例xi的真实类别，pi为预测输入实例xi是正样本的概率，N是样本总数。</p>
<blockquote>
<p>LogLoss就是逻辑回归的损失函数，而大量深度学习模型的输出层正式逻辑回归或者Softmax，因此采用LogLoss作为评估指标能够非常直观地反应模型损失函数的变化。</p>
</blockquote>
<ul>
<li><p>准确率</p>
<p>对于分类问题，比如CTR问题，准确率（Accuracy）是指分类正确的样本占总样本个数的比例，即：</p></li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yv659pkj20di04ejra.jpg" alt="image-20220609141730897" style="zoom:50%;" /></p>
<p>其中，n_corret代表被正确分类的个数，n_total代表总样本个数。准确率是分类任务中较为直观的评价指标，虽然具有较强的可解释性，但是也存在明显的缺陷：当不同类别的样本的比例非常不均衡时，占比大的类别往往成为影响准确率的最主要因素。例如，如果负样本占比99%，那么分类器将所有样本都预测为负样本，也可以取得99%的准确率。</p>
<ul>
<li><p>精准率和召回率</p>
<p>精准率（Precision）是分类正确的正样本个数占分类器判定为正样本的样本个数的比例。召回率（Recall）是分类正确的正样本个数占真正的正样本个数的比例。</p>
<p>在排序模型中，通常没有一个确定的阈值把预测结果直接判定为正样本或负样本，而是采用TopN排序结果的精准率（Precision@N）和召回率（Recall@N)来衡量排序模型的性能，即认为模型排序的TopN的结果就是模型判定的正样本，然后分别计算Precision@N和Recall<span
class="citation" data-cites="N">@N</span>。</p></li>
</ul>
<p>以TopN推荐为例，令R(u)代表模型根据用户在训练集上的行为给用户计算出的推荐列表，而T(u)代表用户在测试集上的真实喜爱列表。那么推荐结果的精准率的定义如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31ywln0cpj20lc074weo.jpg" alt="image-20220609141853524" style="zoom:50%;" /></p>
<p>从公式上看，它是把用户真实喜爱列表和推荐列表的交集的大小去除以推荐列表的大小，它的意义是计算在所预测的推荐列表中究竟有多少物品是用户感兴趣的。
召回率的定义如下:</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31ywv0m2fj20jg06st8v.jpg" alt="image-20220609141907865" style="zoom:50%;" /></p>
<p>可以看到它与精准率的定义非常相似，唯一不同的是分母变成了用户真实喜爱列表大小。它的意义在于用户真实喜爱列表中的物品中有多少是被推荐算法预测出来的，即真实列表的召回率。
维基百科上的图片很好地展示了Precision和Recall的计算公式，方便记忆:</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yxddde4j20m814f764.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<ul>
<li>上图中圆圈内的代表被选出的样本，用其中的正样本除以被选中的样本总数就是Precision，用其中的正样本除以所有的正样本数量就是Recall。</li>
</ul>
<blockquote>
<p>注意准确率（Accuracy）和精准率（Precision）的区别。</p>
</blockquote>
<p>精准率和召回率是矛盾统一的两个指标：为了提高精准率，分类器需要尽量在“更有把握时”才把样本预测为正样本，即降低了精准率计算公式中的分母部分。但往往会因为过于保守而漏掉很多“没有把握”的正样本，导致召回率过低。
以挑选西瓜为例，若希望将好瓜尽可能多地挑选出来，则可通过增加选瓜的数量来实现，如果将所有的西瓜都选上，那么所有的好瓜也必然都被选上了，这样就会导致Precision很低，但是Recall就会相对较高。若希望选出的瓜中好瓜比例尽可能高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得Recall较低。
为了综合反映Precision和Recall的结果，可以使用F1-score，F1-score是精准率和召回率调和平均值，定义如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31yxwhwrkj20e604gaa3.jpg" alt="image-20220609142008816" style="zoom:50%;" /></p>
<p>用一张图总结一下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zehwvulj20xc0d0dgu.jpg" alt="img" style="zoom:50%;" /></p>
<p>上图左边是混淆矩阵，右边分别是精准率、召回率、F1-score、准确率的计算公式。</p>
<blockquote>
<p>关于混淆矩阵，在下一节有详细介绍。</p>
</blockquote>
<ul>
<li><p>P-R曲线</p>
<p>P-R曲线，顾名思义，其中P代表Precision，R代表Recall。P-R曲线就是根据精确率和召回率而绘制的曲线，一般横轴选择召回率，纵轴选择精确率。对于一个排序模型来说，其P-R曲线上的一个点代表“在某一阈值下，模型将大于该阈值的结果判定为正样本，将小于该阈值的结果判定为负样本时，排序结果对应的召回率和精确率”。整条P-R曲线是通过从高到低移动正样本的阈值生成的。如下图所示，其中包含了3个模型的P-R曲线，其中横轴0点附近代表阈值最大时模型的Precision和Recall。</p></li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zeovw2gj20xa0pogn9.jpg" alt="img" style="zoom:50%;" /></p>
<p>P-R图直观地显示出模型在样本总体上的Precision、Recall。在进行比较的时候，若一个模型的P-R曲线被另外一个模型的P-R曲线完全“包住”，则可断言后者的性能优于前者。如上图中模型A的性能就优于模型C；如果两个模型的P-R曲线出现了交叉，如上图汇总的A和B，则难以一般性地断言两者孰优孰劣，只能在具体的Precision和Recall条件下进行比较。</p>
<ul>
<li><p><strong>ROC曲线</strong></p>
<p>ROC曲线的全称是“the Receiver Operating
Characteristic”曲线，中文译为“受试者工作特征曲线”。ROC曲线最早诞生于军事领域，而后在医学领域应用甚广，“受试者工作特征曲线”这一名称也正是来自于医学领域。</p>
<p>在正式介绍ROC曲线之前，我们先来彻底理解一下混淆矩阵的定义。混淆矩阵中有Positive、Negative、True、False等概念，意义如下：</p></li>
</ul>
<p>​
称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）</p>
<p>​ 预测正确的为True（真），预测错误的为False（伪）</p>
<p>对上述概念进行组合，就产生了如下的混淆矩阵：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zerkkb7j20id0dg3yy.jpg" alt="img" style="zoom:50%;" /></p>
<p>然后，由此引出True Positive Rate（真阳率TPR）、False Positive
Rate（伪阳率FPR）两个概念，计算方式如下：</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z2eftscj204p02z0sk.jpg"
alt="image-20220609142427911" />
<figcaption aria-hidden="true">image-20220609142427911</figcaption>
</figure>
<p>仔细观察上面的两个式子，发现两个式子的分子其实对应了混淆矩阵的第二行，即预测类别为1的那一行。另外可以发现TPR就是用TP除以TP所在的列，FPR就是用FP除以FP所在的列。二者的含义如下：</p>
<ul>
<li>TPR代表在所有真实类别为1的样本中，预测类别为1的比例</li>
<li>FPR代表在所有真实类别为0的样本中，预测类别为1的比例</li>
</ul>
<p>如果我们计算出了TPR和FPR，那么ROC曲线的绘制就很简单了，ROC曲线的横轴是FPR、纵轴是TPR，当二者相等时，绘制出的曲线是一条直线，如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zevqc3pj20ky0gidg9.jpg" alt="img" style="zoom:50%;" /></p>
<p>表示的意义是：对于不论真实类别是0还是1的样本，模型预测样本为1的概率都是相等的。
换句话说，模型对正例和负例毫无区分能力，做决策和抛硬币没啥区别。因此，我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。</p>
<p>而我们希望模型达到的效果是：对于真实类别为1的样本，模型预测为1的概率（即TPR），要大于真实类别为0而预测类别为1的概率（即FPR），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zey6bt4j20kw0gijrw.jpg" alt="img" style="zoom: 50%;" /></p>
<p>最理想的情况下，既没有真实类别为1而错分为0的样本——TPR一直为1，也没有真实类别为0而错分为1的样本——FPR一直为0，AUC为1，这便是AUC的极大值。
下面举一个小例子，以分类问题为例，预测类别为离散标签，假设8个样本的预测情况如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zf0x57dj20xc04dt8z.jpg" alt="img" style="zoom:50%;" /></p>
<p>得到的混淆矩阵如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zf3r9uuj20gw094t8y.jpg" alt="img" style="zoom:50%;" /></p>
<p>进而计算得到TPR=3/4，FPR=2/4，得到ROC曲线：</p>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zf5o9y0j20jg0eumxm.jpg" alt="img" style="zoom:50%;" /></p>
<p>可以看到这实际上式两段直线组成的曲线，是因为我们只画出了一个关键点。
如果对于CTR任务，预测的结果是一个概率值，那应该如何画出ROC曲线呢？比如预测结果如下：</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z4nawqsj20xc04fmxi.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPR，FPR。如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPR，FPR，然后画出关键点，再连线即可得到ROC曲线。
因此，ROC曲线跟P-R曲线一样，也是通过不断地移动模型正样本阈值来生成的。</p>
<ul>
<li><p><strong>AUC</strong></p>
<p>AUC（Area Under Curve）的意思是曲线下的面积。它通常被定义为<a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fbaike.baidu.com%2Fitem%2FROC%E6%9B%B2%E7%BA%BF%2F775606">ROC曲线</a>下与<a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fbaike.baidu.com%2Fitem%2F%E5%9D%90%E6%A0%87%E8%BD%B4%2F9763108">坐标轴</a>围成的<a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fbaike.baidu.com%2Fitem%2F%E9%9D%A2%E7%A7%AF%2F100551">面积</a>，显然这个面积的数值不会大于1（但是这个曲线也不一定是ROC，也可以是前面提及的P-R曲线）。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围在0.5和1之间。AUC越接近1.0，检测方法真实性越高;等于0.5时，则真实性最低，无应用价值。我们往往使用AUC值作为模型的评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。</p>
<p>综上，<strong>AUC是衡量二分类模型优劣的一种评价指标，表示预测的正例排在负例前面的概率。</strong></p></li>
<li><p><strong>mAP</strong></p>
<p>平均精度均值（mean Average Precision，
mAP）是另一个在推荐系统、信息领域中常用的评估指标。该指标其实是对平均精度（Average
Precision，AP）的再次平均，因此在计算mAP之前，我们先了解一下什么是平均精度。</p>
<p>假设推荐系统对某一用户测试集的排序结果如下：</p></li>
</ul>
<table>
<thead>
<tr>
<th>推荐序列</th>
<th>N=1</th>
<th>N=2</th>
<th>N=3</th>
<th>N=4</th>
<th>N=5</th>
<th>N=6</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实标签</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>其中，1代表正样本，0代表负样本。我们来计算下它们的Precision。如下表所示：</p>
<table>
<thead>
<tr>
<th>推荐序列</th>
<th>N=1</th>
<th>N=2</th>
<th>N=3</th>
<th>N=4</th>
<th>N=5</th>
<th>N=6</th>
</tr>
</thead>
<tbody>
<tr>
<td>真实标签</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>Precision@N</td>
<td>1/1</td>
<td>1/2</td>
<td>1/3</td>
<td>2/4</td>
<td>3/5</td>
<td>4/6</td>
</tr>
</tbody>
</table>
<p>AP的计算只取正样本处的Precision进行平均，即AP =
(1/1+2/4+3/5+4/6)/4=0.6917。如果推荐系统对测试集中每个用户都进行样本排序，那么每个用户都会计算出一个AP值，再对所有用户的AP值进行平均，就得到了mAP。也就是说，mAP是对精确度平均的平均。
值得注意的是，mAP的计算方法和P-R曲线、ROC曲线的计算方式完全不同，因为mAP需要对每个用户的样本进行分用户排序，而P-R曲线和ROC曲线均是对全量测试样本进行排序。</p>
<h1 id="section"></h1>
<h1 id="实例">实例</h1>
<p>下面以一个经典的莺尾花分类的例子来展示各种指标的计算。
导入莺尾花数据，使用Holdout检验，将数据集随机划分成训练集和测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm, datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add noisy features</span></span><br><span class="line">random_state = np.random.RandomState(<span class="number">0</span>)</span><br><span class="line">n_samples, n_features = X.shape</span><br><span class="line">X = np.c_[X, random_state.randn(n_samples, <span class="number">200</span> * n_features)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Limit to the two first classes, and split into training and test</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X[y &lt; <span class="number">2</span>], y[y &lt; <span class="number">2</span>],</span><br><span class="line">                                                    test_size=<span class="number">.5</span>,</span><br><span class="line">                                                    random_state=random_state)</span><br></pre></td></tr></table></figure>
<p>创建一个线性SVM分类器，计算测试数据到决策平面的距离以及对测试数据进行预测：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a simple classifier</span></span><br><span class="line">classifier = svm.LinearSVC(random_state=random_state)</span><br><span class="line">classifier.fit(X_train, y_train)</span><br><span class="line">y_score = classifier.decision_function(X_test)</span><br><span class="line">y_predict = classifier.predict(X_test)</span><br></pre></td></tr></table></figure>
<p>计算准确率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">accuracy = accuracy_score(y_test, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy: &quot;</span>, accuracy)</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z5xdv3pj208c01o0sj.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>计算精准率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_score</span><br><span class="line">precision = precision_score(y_test, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Precision: &quot;</span>, precision)</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z672ruxj208s01udfn.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>计算召回率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> recall_score</span><br><span class="line">recall = recall_score(y_test, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Recall: &quot;</span>, recall)</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z6uhwbkj20d401ot8l.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>计算F1-Score：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score</span><br><span class="line">F1_score = f1_score(y_test, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;F1-score: &quot;</span>, F1_score)</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z7rbrxhj20em01smx1.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>计算精确率均值AP：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> average_precision_score</span><br><span class="line">average_precision = average_precision_score(y_test, y_score)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Average precision: &#123;0:0.2f&#125;&#x27;</span>.<span class="built_in">format</span>(average_precision))</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z812ynpj20c401ojr8.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>计算混淆矩阵：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">confusion_matrix = confusion_matrix(y_test, y_predict)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Confusion Matrix: \n&quot;</span>, confusion_matrix)</span><br></pre></td></tr></table></figure>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z8af21uj208m03ggli.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制P-R曲线，并且计算AUC：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve, auc</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> plot_precision_recall_curve</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">disp = plot_precision_recall_curve(classifier, X_test, y_test)</span><br><span class="line">disp.ax_.set_title(<span class="string">&#x27;P-R Example&#x27;</span>)</span><br><span class="line"></span><br><span class="line">precision, recall, _thresholds = precision_recall_curve(y_test, y_predict)</span><br><span class="line">auc = auc(recall, precision)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;AUC: &quot;</span>, auc)</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31zfd59juj20ue0ksq3p.jpg" alt="img" style="zoom:50%;" /></p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z8tjgbcj20ge01yt8n.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>绘制ROC曲线并且计算AUC：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score, auc, roc_curve</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">fpr, tpr, thresholds = roc_curve(y_test, y_score)</span><br><span class="line">roc_auc = auc(fpr, tpr)  <span class="comment">#auc为Roc曲线下的面积</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#开始画ROC曲线</span></span><br><span class="line">plt.plot(fpr, tpr, <span class="string">&#x27;b&#x27;</span>,label=<span class="string">&#x27;AUC = %0.2f&#x27;</span>% roc_auc)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;lower right&#x27;</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>],<span class="string">&#x27;r--&#x27;</span>)</span><br><span class="line">plt.xlim([-<span class="number">0.1</span>,<span class="number">1.1</span>])</span><br><span class="line">plt.ylim([-<span class="number">0.1</span>,<span class="number">1.1</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;FPR&#x27;</span>) <span class="comment">#横坐标是fpr</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;TPR&#x27;</span>)  <span class="comment">#纵坐标是tpr</span></span><br><span class="line">plt.title(<span class="string">&#x27;ROC Example&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z99o8w6j20rc0jc0tf.jpg" alt="img" style="zoom:50%;" /></p>
<h1 id="ab测试与线上评估指标">A/B测试与线上评估指标</h1>
<p>无论离线评估如何仿真线上环境，终究无法完全还原线上的所有变量。对几乎所有的互联网公司来说，线上A/B测试都是验证新模块、新功能、新产品是否有效的主要测试方法。</p>
<h2 id="ab测试">A/B测试</h2>
<p>A/B测试又称为“分流测试”或“分桶测试”，是一个随机实验，通常被分为实验组和对照组。在利用控制变量法保持单一变量的前提下，将A、B两组数据进行对比，得出实验结论。具体到互联网场景下的算法测试中，可以将用户随机分成实验组和对照组，对实验组的用户施以新模型，对对照组的用户施以旧模型，比较实验组和对照组在各线上评估指标上的差异。可以由下图来展示：</p>
<figure>
<img
src="https://tva1.sinaimg.cn/large/e6c9d24ely1h31z9vompuj20gt085glv.jpg"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>上图中用户被随机均分成两组，橘色和绿色代表被控制的变量，最右侧是转化率。通过这种方式可以看到，系统中单个变量对系统产生的整体影响。
相对离线评估而言，线上A/B测试无法被替代的原因主要有以下三点：</p>
<ul>
<li><strong>离线评估无法完全消除数据有偏现象的影响，因此得出的离线评估结果无法完全替代线上评估结果。</strong></li>
<li><strong>离线评估无法完全还原线上的工程环境。</strong>一般来说，离线评估往往不考虑线上的延迟、数据丢失、标签缺失等情况。因此，离线评估环境只能说是理想状态下的工程环境，得出的评估结果存在一定的失真现象。</li>
<li><strong>线上系统的某些商业指标在离线评估中无法计算</strong>。离线评估一般针对模型本身进行评估，无法直接获得与模型相关的其他指标，特别是商业指标。也新的推荐模型为例，离线评估关注的往往是ROC曲线、PR曲线等的改进，而线上评估可以全面了解该推荐模型带来的用户点击率、留存时长、PV访问量等的变化。这些都需要由A/B测试进行全面评估。</li>
</ul>
<h2 id="线上ab测试的评估指标">线上A/B测试的评估指标</h2>
<p>一般来讲，A/B测试都是模型上线前的最后一道测试，通过A/B测试检验的模型将直接服务于线上用户，完成公司的商业目标。因此，A/B测试的指标与线上业务的核心指标保持一致。
下表列出了电商类推荐模型、新闻类推荐模型、视频类推荐模型的线上A/B测试的主要评估指标：</p>
<table>
<colgroup>
<col style="width: 18%" />
<col style="width: 81%" />
</colgroup>
<thead>
<tr>
<th>推荐系统类别</th>
<th>线上A/B测试评估指标</th>
</tr>
</thead>
<tbody>
<tr>
<td>电商类推荐模型</td>
<td>点击率、转化率、客单价（用户平均消费金额）</td>
</tr>
<tr>
<td>新闻类推荐模型</td>
<td>留存率（x日后仍活跃的用户数/x日前的用户数）、平均停留时长、平均点击个数</td>
</tr>
<tr>
<td>视频类推荐模型</td>
<td>播放完成率（播放时长/视频时长）、平均播放时长、播放总时长</td>
</tr>
</tbody>
</table>
<p>线上A/B测试的指标与离线评估指标有较大差异。离线评估不具备直接计算业务核心指标的条件，因此退而求其次，选择了偏向于技术评估的模型相关指标。但在公司层面，更关心能够驱动业务发展的核心指标。因此，在具备线上测试环境时，利用A/B测试验证模型对业务核心指标的提升效果是有必要的。从这个意义上讲，线上A/B测试的作用是离线评估无法替代的。</p>
<h1 id="参考">参考</h1>
<ul>
<li>《机器学习》 -- 周志华</li>
<li>《推荐系统实战》-- 项亮</li>
<li>《深度学习推荐系统》-- 王喆</li>
<li>https://www.jianshu.com/p/5df19746daf9</li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.zhihu.com%2Fquestion%2F39840928">https://www.zhihu.com/question/39840928</a></li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fbaike.baidu.com%2Fitem%2FAUC%2F19282953%3Ffr%3Daladdin">https://baike.baidu.com/item/AUC/19282953?fr=aladdin</a></li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FPrecision_and_recall">https://en.wikipedia.org/wiki/Precision_and_recall</a></li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fblog.csdn.net%2Fbqw18744018044%2Farticle%2Fdetails%2F81024520">https://blog.csdn.net/bqw18744018044/article/details/81024520</a></li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fscikit-learn.org%2Fstable%2Fmodules%2Fclasses.html%23module-sklearn.model_selection">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection</a></li>
<li><a
target="_blank" rel="noopener" href="https://links.jianshu.com/go?to=https%3A%2F%2Fscikit-learn.org%2Fstable%2Fauto_examples%2Fmodel_selection%2Fplot_precision_recall.html">https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html</a></li>
</ul>

      </div>
    </div>
    
      <script src='https://unpkg.com/mermaid@latest/dist/mermaid.min.js'></script>
      <script>
        if (window.mermaid) {
          mermaid.initialize({"startOnload":true});
        }
      </script>
    
  </article>
  <div class="post__foot">
    
      <div class="like-author">
  <input type="checkbox" id="likeCode" />
  <div class="author-face">
    <img height="100px"
         width="100px"
         id="front-face"
         alt="author face"
         src="/images/author-face.jpg" />
    <img height="100px"
         width="100px"
         id="back-face"
         alt="like code"
         src="/images/pay-code.jpg" />
  </div>
  <div class="like-text">“给作者倒杯卡布奇诺”</div>
  <label for="likeCode" class="like-btn">
    <svg viewBox="0 0 1024 1024"
         width="20px"
         style="margin-right: 10px"
         height="20px">
      <path d="M466.88 908.96L113.824 563.296a270.08 270.08 0 0 1 0-387.392c108.8-106.56 284.896-106.56 393.696 0 1.504 1.472 2.976 2.944 4.448 4.48 1.472-1.536 2.944-3.008 4.448-4.48 108.8-106.56 284.896-106.56 393.696 0a269.952 269.952 0 0 1 34.016 347.072l-387.392 385.6a64 64 0 0 1-89.92 0.384z" p-id="13650" fill="#ee4242" />
    </svg>
    喜欢作者
  </label>
</div>

    
    <div class="post-nav">
  
    <a class="post-nav-item-left" href="/2022/01/10/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/">
      <div class="text-align">
        <svg t="1670570876164"
             class="icon"
             viewBox="0 0 1024 1024"
             width="16"
             height="16">
          <path d="M384 512L731.733333 202.666667c17.066667-14.933333 19.2-42.666667 4.266667-59.733334-14.933333-17.066667-42.666667-19.2-59.733333-4.266666l-384 341.333333c-10.666667 8.533333-14.933333 19.2-14.933334 32s4.266667 23.466667 14.933334 32l384 341.333333c8.533333 6.4 19.2 10.666667 27.733333 10.666667 12.8 0 23.466667-4.266667 32-14.933333 14.933333-17.066667 14.933333-44.8-4.266667-59.733334L384 512z" p-id="14596" />
        </svg>
        <span class="text-small">上一篇</span>
      </div>
      <div>第一篇博客</div>
    </a>
  
  <div class="vhr"></div>
  
    <div class="post-nav-item-right"></div>
  
</div>

    
    
  </div>

    </div>
    <div class="foot">
  <div class="foot-inner">
    <div class="foot__head">
      
        <div class="foot-line">
          <div class="matts">今</div><div class="matts">夜</div><div class="matts">无</div><div class="matts">眠</div>
        </div>
      
        <div class="foot-line">
          <div class="matts">睡</div><div class="matts">意</div><div class="matts">全</div><div class="matts">无</div>
        </div>
      
    </div>
    <div class="foot__body">
      
        <div class="foot-item">
          <div class="foot-item__head">朋友</div>
          <div class="foot-item__body">
            
            


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/icon/icon-link.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://moyanxinxu.github.io/unlock-hf/">unlock-hf</a>
          </div>
        
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/icon/icon-link+.svg" />
            <a class="foot-link" href="mailto:873101411@qq.com?subject=申请http://example.com的友链">申请友链</a>
          </div>
        
      
        
        
      
        
        
      
    </div>
  


          </div>
        </div>
      
      
        <div class="foot-item">
          <div class="foot-item__head">账号</div>
          <div class="foot-item__body">
            


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-github.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://github.com/viserion-nlper">viserion-nlper</a>
          </div>
        
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-wx.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Fq9ZIUwZvMNx2kSahz8zEw">HanLP.com</a>
          </div>
        
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/logo-zh.svg" />
            <a class="foot-link" target="_blank" rel="noopener" href="https://www.zhihu.com/people/shuo-hao-jin-ye-bu-dian-yan">点烟侠</a>
          </div>
        
      
        
        
      
    </div>
  


          </div>
        </div>
      
      <div class="foot-item">
        <div class="foot-item__head">联系</div>
        <div class="foot-item__body">
          


  
  
    <div class="foot-link-group">
      
        
        
          <div class="text">
            <img alt="link"
                 height="20px"
                 width="20px"
                 src="/images/icon/icon-email.svg" />
            <a class="foot-link" href="mailto:name@example.com">name@example.com</a>
          </div>
        
      
        
        
      
        
        
      
        
        
      
    </div>
  


        </div>
      </div>
    </div>
    <div class="copyright">
      <a href="http://example.com">思想放牧之地</a> &nbsp;|&nbsp;由&nbsp;<a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>&nbsp;及&nbsp;
      <svg width="20" height="20" viewBox="0 0 725 725">
        <path fill-rule="evenodd" fill="rgb(221, 221, 221)" d="M145.870,236.632 L396.955,103.578 L431.292,419.44 L156.600,522.53 L145.870,236.632 Z" />
        <path fill-rule="evenodd" fill="rgb(159, 159, 159)" d="M396.955,103.578 L564.345,234.486 L611.558,513.469 L431.292,419.44 L396.955,103.578 Z" />
        <path fill-rule="evenodd" fill="rgb(0, 0, 0)" d="M431.292,419.44 L611.558,513.469 L358.327,595.18 L156.600,522.53 L431.292,419.44 Z" />
      </svg>
      <a target="_blank" rel="noopener" href="https://github.com/hooozen/hexo-theme-tranquility">致远</a>&nbsp;驱动
    </div>
  </div>
</div>

    
    
      <script src="/js/search.js"></script>
      <script>searchInitialize("/search.json")</script>
    
    <script src="/js/copy-code.js"></script>
    
  

  </body>
</html>
